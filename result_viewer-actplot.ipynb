{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T23:24:22.348205Z",
     "start_time": "2020-10-26T23:11:32.889541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 201026_19-23-06-A4H can not import\n",
      "Ran out of input\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 109, in loader\n",
      "    try:\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 114, in loader\n",
      "    # disp_name='dataset:%s date:%s %s'%(run_info['dataset'],run_info['run_date'], evalres[0].shortrunname)\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 341, in load\n",
      "    **version_dependent_kwargs,\n",
      "EOFError: Ran out of input\n",
      "File cache can not import\n",
      "[Errno 2] No such file or directory: 'save_data/cache/data.pkl.lz4'\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 108, in loader\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 318, in load\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 411, in preprocess_path\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 505, in open_compression_stream\n",
      "    io_stream = lz4.frame.open(stream, mode=mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 831, in open\n",
      "    return_bytearray=return_bytearray,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 510, in __init__\n",
      "    self._fp = builtins.open(filename, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'save_data/cache/info.pkl.lz4'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 114, in loader\n",
      "    # disp_name='dataset:%s date:%s %s'%(run_info['dataset'],run_info['run_date'], evalres[0].shortrunname)\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 318, in load\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 411, in preprocess_path\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 505, in open_compression_stream\n",
      "    io_stream = lz4.frame.open(stream, mode=mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 831, in open\n",
      "    return_bytearray=return_bytearray,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 510, in __init__\n",
      "    self._fp = builtins.open(filename, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'save_data/cache/data.pkl.lz4'\n",
      "File testdata can not import\n",
      "string indices must be integers\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 108, in loader\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 318, in load\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 411, in preprocess_path\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 505, in open_compression_stream\n",
      "    io_stream = lz4.frame.open(stream, mode=mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 831, in open\n",
      "    return_bytearray=return_bytearray,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 510, in __init__\n",
      "    self._fp = builtins.open(filename, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'save_data/testdata/info.pkl.lz4'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 118, in loader\n",
      "    logger.warn('File %s can not import'%item)\n",
      "TypeError: string indices must be integers\n",
      "File ward-b can not import\n",
      "string indices must be integers\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 108, in loader\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 318, in load\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 411, in preprocess_path\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 505, in open_compression_stream\n",
      "    io_stream = lz4.frame.open(stream, mode=mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 831, in open\n",
      "    return_bytearray=return_bytearray,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 510, in __init__\n",
      "    self._fp = builtins.open(filename, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'save_data/ward-b/info.pkl.lz4'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 118, in loader\n",
      "    logger.warn('File %s can not import'%item)\n",
      "TypeError: string indices must be integers\n",
      "File ward-a can not import\n",
      "string indices must be integers\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 108, in loader\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 318, in load\n",
      "    **kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 411, in preprocess_path\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/utils.py\", line 505, in open_compression_stream\n",
      "    io_stream = lz4.frame.open(stream, mode=mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 831, in open\n",
      "    return_bytearray=return_bytearray,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 510, in __init__\n",
      "    self._fp = builtins.open(filename, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'save_data/ward-a/info.pkl.lz4'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 118, in loader\n",
      "    logger.warn('File %s can not import'%item)\n",
      "TypeError: string indices must be integers\n",
      "File 200515_23-58-43-A4H can not import\n",
      "Ran out of input\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 109, in loader\n",
      "    try:\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 114, in loader\n",
      "    # disp_name='dataset:%s date:%s %s'%(run_info['dataset'],run_info['run_date'], evalres[0].shortrunname)\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 341, in load\n",
      "    **version_dependent_kwargs,\n",
      "EOFError: Ran out of input\n",
      "File 200515_23-56-13-A4H can not import\n",
      "Ran out of input\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 109, in loader\n",
      "    try:\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 114, in loader\n",
      "    # disp_name='dataset:%s date:%s %s'%(run_info['dataset'],run_info['run_date'], evalres[0].shortrunname)\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 341, in load\n",
      "    **version_dependent_kwargs,\n",
      "EOFError: Ran out of input\n",
      "File 200515_16-33-26-A4H can not import\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressed file ended before the end-of-stream marker was reached\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 109, in loader\n",
      "    try:\n",
      "TypeError: list indices must be integers or slices, not str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/UnifiedAR/result_analyse/resultloader.py\", line 114, in loader\n",
      "    # disp_name='dataset:%s date:%s %s'%(run_info['dataset'],run_info['run_date'], evalres[0].shortrunname)\n",
      "  File \"/workspace/UnifiedAR/general/utils.py\", line 162, in loadState\n",
      "    # if(name=='data'):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/compress_pickle/compress_pickle.py\", line 341, in load\n",
      "    **version_dependent_kwargs,\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/lz4/frame/__init__.py\", line 618, in peek\n",
      "    return self._buffer.peek(size)\n",
      "  File \"/opt/conda/lib/python3.6/_compression.py\", line 68, in readinto\n",
      "    data = self.read(len(byte_view))\n",
      "  File \"/opt/conda/lib/python3.6/_compression.py\", line 99, in read\n",
      "    raise EOFError(\"Compressed file ended before the \"\n",
      "EOFError: Compressed file ended before the end-of-stream marker was reached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8321b49c1a90473eb2faffff59fed832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file', options=(('dataset:Home1 date:201026_18-23-50 SimplePreproc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib widget\n",
    "%pylab inline\n",
    "# pylab.rcParams['figure.figsize'] = (8, 6)\n",
    "import  general.utils as utils\n",
    "import  datatool.testdata as testdata\n",
    "import result_analyse.visualisation as vs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import  general.utils as utils\n",
    "import result_analyse.resultloader\n",
    "import result_analyse.visualisation as vs\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from metric.CMbasedMetric import CMbasedMetric\n",
    "from metric.event_confusion_matrix import event_confusion_matrix\n",
    "\n",
    "import combiner.SimpleCombiner\n",
    "comb=combiner.SimpleCombiner.EmptyCombiner()\n",
    "\n",
    "def showres(dataset,real_events,pred_events,acts,weight,duration=None):\n",
    "    real_events=vs.filterTime(real_events,duration)\n",
    "    pred_events=vs.filterTime(pred_events,duration)\n",
    "#     print(real_events)\n",
    "#     print(pred_events)\n",
    "#     utils.saveState((real_events,pred_events),'ali')\n",
    "    event_cm     =event_confusion_matrix(real_events,pred_events,acts)\n",
    "    quality      =CMbasedMetric(event_cm,'macro',None)\n",
    "    quality_w    =CMbasedMetric(event_cm,'macro',weight)\n",
    "    quality2     =CMbasedMetric(event_cm)\n",
    "    print(f'quality={quality[\"f1\"]} wq={quality_w[\"f1\"]}')\n",
    "    \n",
    "#     print([f'{acts[i]}=>f={quality2[\"f1\"][i]} p={quality2[\"precision\"][i]} r={quality2[\"recall\"][i]}' for i in range(len(acts))])\n",
    "    \n",
    "    # visualize(dataset)\n",
    "    #vs.remove_gaps(real_events,pred_events)\n",
    "    print('visualizing real and pred')\n",
    "    vs.plotJoinAct(dataset,real_events,pred_events)\n",
    "    from matplotlib.pylab import plt\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def groupize(datasetdscr,acts):\n",
    "    #gacts=[[a] for a in datasetdscr.activities_map]\n",
    "    #gacts.append([a for a in datasetdscr.activities_map])\n",
    "    gacts=[[a] for a in acts[1:]]\n",
    "    gacts.append([a for a in acts])\n",
    "    return gacts\n",
    "\n",
    "@interact\n",
    "def result_selector(file=result_analyse.resultloader.get_runs_summary()):\n",
    "    if(file==None):return\n",
    "    print('Analysing ',file)\n",
    "#     info=utils.loadState(file,'info')\n",
    "#     for i in info:\n",
    "#         print(i,info[i])\n",
    "    @interact_manual\n",
    "    def continue_select():\n",
    "        savedfile=file\n",
    "        #result='A4Hr1'\n",
    "        run_info,dataset,evalres=utils.loadState(savedfile)\n",
    "        global a\n",
    "        a=run_info,dataset,evalres\n",
    "        print(run_info)\n",
    "        #print(dataset)\n",
    "        acts=[a for a in dataset.activities_map]\n",
    "        gacts=groupize(dataset,acts)\n",
    "        for fold in range(len(evalres)):\n",
    "                global foldres\n",
    "                foldres=evalres[fold]['test']\n",
    "                print(f'fold----------{fold}')\n",
    "         #       print(foldres)\n",
    "                \n",
    "                real_events=foldres.real_events\n",
    "                pred_events=foldres.pred_events\n",
    "                quality=foldres.quality\n",
    "                s=real_events.iloc[0]['StartTime']\n",
    "                e=s+pd.Timedelta('2 day')\n",
    "\n",
    "    #             pred_events2=comb.combine2(foldres.times, foldres.predicted)\n",
    "                showres(dataset,real_events,pred_events,acts,None,duration=[s,e])\n",
    "        \n",
    "                return\n",
    "    #             showres(dataset,real_events,pred_events2,acts,None,duration=[s,e])\n",
    "                print('Evalution quality fold=%d is %s' % (fold, quality))\n",
    "\n",
    "\n",
    "#                 for gindx,tacts in enumerate(gacts):\n",
    "#                 for gindx in foldres.functions:\n",
    "#                     weight=np.ones(len(acts))\n",
    "#                     for a in tacts:weight[a]=20\n",
    "#                 print('seg %s'% (foldres.functions['segmentor']))\n",
    "\n",
    "                print(foldres.quality)\n",
    "    #             print(foldres.results[gindx].event_cm)\n",
    "    #             print(foldres.results[gindx].predicted_classes)\n",
    "    #             print(foldres.results[gindx].Sdata.label)\n",
    "#                 if(gindx+1 in dataset.activities_map):\n",
    "#                     print(f'--------------{dataset.activities_map[gindx+1]}----------------')\n",
    "\n",
    "                real_events=foldres.real_events\n",
    "                pred_events=foldres.pred_events\n",
    "\n",
    "                times=[]\n",
    "                act_data=np.zeros((len(pred_events),12))\n",
    "                for i in range(len(pred_events)):\n",
    "                    p=pred_events.iloc[i]\n",
    "                    times.append({'begin':p['StartTime'],'end':p['EndTime']})\n",
    "                    act_data[i,p['Activity']]=1\n",
    "                \n",
    "#                 if hasattr(foldres.results[gindx],'Sdata'):\n",
    "#                     Sdata=foldres.results[gindx].Sdata\n",
    "#                     pred_events2=comb.combine(Sdata.s_event_list,Sdata.set_window, foldres.results[gindx].predicted)\n",
    "                weight=None\n",
    "                showres(dataset,real_events,pred_events,acts,weight,duration=[s,e])            \n",
    "                pred_events2=comb.combine2(times,act_data)\n",
    "                showres(dataset,real_events,pred_events2,acts,weight,duration=[s,e])\n",
    "\n",
    "\n",
    "\n",
    "        #             print(confusion_matrix(evalres[i].results[f].Sdata.label,evalres[i].results[f].predicted_classes))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
