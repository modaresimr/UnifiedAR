{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T05:20:37.801253Z",
     "start_time": "2021-03-27T05:20:37.718605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datatool.seddata\n",
    "import general.utils\n",
    "import result_analyse.kfold_analyse as an\n",
    "import metric.Metrics\n",
    "import result_analyse.visualisation as vs\n",
    "from SED.evaluation_measures import psds_score, compute_psds_from_operating_points, compute_metrics\n",
    "import SED.evaluation_measures \n",
    "import psds_eval\n",
    "\n",
    "rootFolder='/workspace/sed2020/'   \n",
    "    \n",
    "@interact\n",
    "def result_selector(gtf=os.listdir(f'{rootFolder}/metadata/')):\n",
    "    typ=gtf.split('.')[0]\n",
    "    gtf=f'{rootFolder}/metadata/{gtf}'\n",
    "    groundtruth=pd.read_csv(gtf,delimiter='\\t')\n",
    "    groundtruth_dataset=datatool.seddata.SED(gtf,typ,None)\n",
    "    \n",
    "    groundtruth_dataset.load()\n",
    "    meta_dur_df=pd.DataFrame(columns=['filename','duration'])\n",
    "    meta_dur_df['filename']=groundtruth['filename']\n",
    "    meta_dur_df['duration']=10\n",
    "    @interact\n",
    "    def result_selector(team=sorted(os.listdir(f'{rootFolder}/submissions/'))):\n",
    "        @interact\n",
    "        def result_selector(code=sorted([x for x in os.listdir(f'{rootFolder}/submissions/{team}') if os.path.isfile(f'{rootFolder}/submissions/{team}/{x}/{typ}/{x}.output.tsv')]) ):\n",
    "            title=code.replace('_task4','')\n",
    "            base_prediction_path=f'{rootFolder}/submissions/{team}/{code}/{typ}/'\n",
    "            pef = f'{base_prediction_path}/{code}.output.tsv'\n",
    "            psdsf = f'{base_prediction_path}/{code}.output_PSDS'            \n",
    "            print(gtf,pef,psdsf)\n",
    "#             get_single_result(pef,groundtruth,meta_dur_df,psdsf, groundtruth_dataset)\n",
    "            return\n",
    "            computeGem(pef, groundtruth_dataset)\n",
    "            \n",
    "            \n",
    "            # Evaluate a single prediction\n",
    "            single_predictions = pd.read_csv(pef, sep=\"\\t\")\n",
    "            compute_metrics(single_predictions, groundtruth,meta_dur_df)\n",
    "            \n",
    "            \n",
    "\n",
    "            # Evaluate predictions with multiple thresholds (better). Need a list of predictions.\n",
    "            prediction_list_path = glob.glob(os.path.join(psdsf, \"*.tsv\"))\n",
    "            list_predictions = []\n",
    "            for fname in prediction_list_path:\n",
    "                pred_df = pd.read_csv(fname, sep=\"\\t\")\n",
    "                list_predictions.append(pred_df)\n",
    "            psds = compute_psds_from_operating_points(list_predictions, groundtruth, meta_dur_df)\n",
    "            psds_score(psds, filename_roc_curves=os.path.join(base_prediction_path, \"figures/psds_roc.png\"))\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T13:14:06.734895Z",
     "start_time": "2021-03-07T13:14:06.726353Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import datatool.seddata\n",
    "import general.utils\n",
    "import result_analyse.kfold_analyse as an\n",
    "import metric.Metrics\n",
    "import result_analyse.visualisation as vs\n",
    "from SED.evaluation_measures import psds_score, compute_psds_from_operating_points, compute_metrics\n",
    "import SED.evaluation_measures \n",
    "import psds_eval\n",
    "rootFolder='/workspace/sed2020/'\n",
    "\n",
    "\n",
    "# res1=get_single_result('/workspace/sed2020//metadata/public.tsv','/workspace/sed2020//submissions/CTK_NU/CTK_NU_task4_SED_1/public//CTK_NU_task4_SED_1.output.tsv','/workspace/sed2020//submissions/CTK_NU/CTK_NU_task4_SED_1/public//CTK_NU_task4_SED_1.output_PSDS')\n",
    "# res2=get_single_result('/workspace/sed2020//metadata/public.tsv','/workspace/sed2020//submissions/CTK_NU/CTK_NU_task4_SED_3/public//CTK_NU_task4_SED_3.output.tsv','/workspace/sed2020//submissions/CTK_NU/CTK_NU_task4_SED_1/public//CTK_NU_task4_SED_3.output_PSDS')\n",
    "\n",
    "# total=pd.DataFrame({'res1':{c:res1[c].loc['macro-avg']['f1'] for c in res1.keys()},\n",
    "#                    'res2':{c:res2[c].loc['macro-avg']['f1'] for c in res2.keys()} }).T\n",
    "\n",
    "# print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T09:17:23.316167Z",
     "start_time": "2021-03-26T09:17:23.311444Z"
    }
   },
   "source": [
    "# Run All submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T21:26:14.747865Z",
     "start_time": "2021-03-30T21:25:09.445756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#@interact\n",
    "#def result_selector(gtf=os.listdir(f'{rootFolder}/metadata/')):\n",
    "import SED.my_eval\n",
    "gtf='public.tsv'\n",
    "rootFolder='/workspace/sed2020/'\n",
    "typ=gtf.split('.')[0]\n",
    "gtf=f'{rootFolder}/metadata/{gtf}'\n",
    "# meta_dur_df=pd.DataFrame(columns=['filename','duration'])\n",
    "# meta_dur_df['filename']=groundtruth['filename']\n",
    "# meta_dur_df['duration']=10\n",
    "\n",
    "l=['Miyazaki_NU_task4_SED_1','Miyazaki_NU_task4_SED_3','Hao_CQU_task4_SED_4','Koh_NTHU_task4_SED_3','Liu_thinkit_task4_SED_3','Miyazaki_NU_task4_SED_2','Ebbers_UPB_task4_SED_1','Hao_CQU_task4_SED_2','CTK_NU_task4_SED_4','Yao_UESTC_task4_SED_3']\n",
    "# l=['Ebbers_UPB_task4_SED_1']\n",
    "total_dic={}\n",
    "for team in sorted(os.listdir(f'{rootFolder}/submissions/')):\n",
    "    print(f'analysing team {team}')\n",
    "    for code in sorted(os.listdir(f'{rootFolder}/submissions/{team}')):\n",
    "        if not(code in l):continue\n",
    "        print(f'    {code}')\n",
    "        \n",
    "        base_prediction_path=f'{rootFolder}/submissions/{team}/{code}/{typ}/'\n",
    "        pef = f'{base_prediction_path}/{code}.output.tsv'\n",
    "        if not(os.path.isfile(pef)):\n",
    "            all=[x for x in os.listdir(base_prediction_path) if '.output.tsv' in x]\n",
    "            if len(all)>0:\n",
    "                pef=f'{base_prediction_path}/{all[0]}'\n",
    "            else:\n",
    "                print(pef)\n",
    "                continue\n",
    "        title=code.replace('_task4','')\n",
    "        try:\n",
    "            res1=SED.my_eval.get_single_result(gtf,pef,debug=0)\n",
    "            total_dic[title]=res1\n",
    "#             print(res1['detection'])\n",
    "#             break\n",
    "        except Exception as e:\n",
    "            print('Error! submission is ignored',e)\n",
    "#         if('gem' in res1):\n",
    "#             for k in res1['gem'].keys():\n",
    "#                 total_dic[title][f'gem-{k}']=res1['gem'].loc['avg'][k]\n",
    "#     break\n",
    "\n",
    "fs={s:{c:total_dic[s][c].loc['macro-avg']['f1'] for c in total_dic[s]} for s in total_dic  }\n",
    "total=pd.DataFrame(fs).T\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart compare all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T11:53:31.772937Z",
     "start_time": "2021-03-31T11:53:31.345121Z"
    }
   },
   "outputs": [],
   "source": [
    "def aliplot(total):\n",
    "    from matplotlib.pylab import plt\n",
    "    w={'detection':1.,\n",
    "       'uniformity':1.,\n",
    "       'total duration':1.,\n",
    "       'relative duration':1.,\n",
    "#        'boundary onset':1.\n",
    "      }\n",
    "    wsum=sum(w.values())\n",
    "    for wi in w:\n",
    "        if('our' in total): total['our']+=w[wi]/wsum*total[wi]\n",
    "        else: total['our']=w[wi]/wsum*total[wi]\n",
    "#     total['tmp']=total['total duration']/total['detection']\n",
    "#     print(total[['tmp','relative duration']])\n",
    "#     print(total['gem'])\n",
    "    total=total.sort_values(['collar'])\n",
    "#     total=total[-10:]\n",
    "#     total=total[7:]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, len(total)/3), sharey=True)\n",
    "#     total=total.sort_values(['gem'])\n",
    "    import pandas\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    # colorcycle = cycler(color=['blue', 'orange', 'green', 'magenta'])\n",
    "    # Or use the default color cycle:\n",
    "    # colorcycle = cycler(color=plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "\n",
    "\n",
    "    ind = np.arange(len(total))\n",
    "    def myplot(ax,colis):\n",
    "        cols=total.columns[colis]\n",
    "        width = .9/len(cols)\n",
    "        marker = itertools.cycle(( '^', 'o', 'D', 's','X', '*'))\n",
    "        i=0\n",
    "        ax.grid(True)\n",
    "        # fig, ax = plt.subplots(figsize=(5,10))\n",
    "        for i,x in enumerate(cols):\n",
    "            if x=='y':continue\n",
    "#             ax.plot(total[x],ind+.2 ,label=x,marker=next(marker),alpha=.75)\n",
    "            ax.scatter(total[x],ind+.2 ,label=x,marker=next(marker),alpha=.75)\n",
    "    #         ax.barh(ind+.4-i*width, total[x], width, label=x)#, color='red'\n",
    "\n",
    "        ax.set(yticks=ind + width, yticklabels=[f'S{len(total)-i} : {y.replace(\"_SED\",\"\")}' for i,y in enumerate(total.index)], ylim=[-.5, len(total)-.5])\n",
    "        \n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),\n",
    "                  fancybox=True, shadow=True, ncol=2)\n",
    "        ax.set_xlabel('F1')\n",
    "\n",
    "#     myplot(axs[0],np.append([0,1,len(total.columns)-1],range(2,len(total.columns)-5)))\n",
    "    myplot(axs[0],[0,1,len(total.columns)-1,2,4,5])\n",
    "    # myplot(axs[1],[2])\n",
    "#     myplot(axs[1],range(len(total.columns)-9,len(total.columns)-1))\n",
    "#     myplot(axs[1],[8,11,12,13])\n",
    "    myplot(axs[1],[8,11,12,13,14])\n",
    "    \n",
    "    # print(total)\n",
    "# \n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "fs={s:{c:total_dic[s][c].loc['macro-avg']['f1'] for c in total_dic[s]} for s in total_dic  }\n",
    "total=pd.DataFrame(fs).T\n",
    "total\n",
    "aliplot(total)\n",
    "# total.sort_values(['events'],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T09:03:24.613134Z",
     "start_time": "2021-03-29T09:03:24.468482Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fs={s:{c:total_dic[s][c].loc['macro-avg']['f1'] for c in total_dic[s]} for s in total_dic  }\n",
    "total=pd.DataFrame(fs).T\n",
    "total\n",
    "# print([c for s in total_dic for c in total_dic[s]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T09:03:18.709794Z",
     "start_time": "2021-03-29T09:03:18.334886Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T09:11:06.715788Z",
     "start_time": "2021-03-29T09:11:06.700845Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('a')\n",
    "# s='Miyazaki_NU_SED_1'\n",
    "s='CTK_NU_SED_1'\n",
    "# print( total_dic[s]['collar'])\n",
    "# print(total_dic[s]['collar'][['Ntp']])\n",
    "team={c:total_dic[s][c] for c in total_dic[s] }\n",
    "# print(team)\n",
    "# aliplot2(team)\n",
    "team['detection']\n",
    "team['detection'].T/team['detection'].sum(axis=1)\n",
    "(team['segment'].T/team['segment'].sum(axis=1)).T.sort_index()[['Ntp','Ntn','Nfp','Nfn']]\n",
    "team['segment'].sort_index()[['Ntp','Ntn','Nfp','Nfn']]\n",
    "# pd.concat(team, axis=1)\n",
    "# print(pd.DataFrame(team).T.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T23:45:09.590700Z",
     "start_time": "2021-03-28T23:45:09.584492Z"
    }
   },
   "outputs": [],
   "source": [
    "(team['total duration'].T/team['total duration'].sum(axis=1)).T.sort_index()[['Ntp','Ntn','Nfp','Nfn']]\n",
    "team['total duration'].sort_index()[['Ntp','Ntn','Nfp','Nfn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-29T07:03:00.963Z"
    }
   },
   "outputs": [],
   "source": [
    "def aliplot2(team):\n",
    "    from matplotlib.pylab import plt\n",
    "    \n",
    "    allmetrics=list(team.keys())\n",
    "    metrics=[allmetrics[m] for m in [0,6,1,2,4,8,9,10,11,12,13,14]]\n",
    "#     total=total[-10:]\n",
    "    fig, axs = plt.subplots(1, len(metrics), figsize=(12, len(team[metrics[0]])/5), sharey=True)\n",
    "#     total=total.sort_values(['gem'])\n",
    "    import pandas\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    # colorcycle = cycler(color=['blue', 'orange', 'green', 'magenta'])\n",
    "    # Or use the default color cycle:\n",
    "    # colorcycle = cycler(color=plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "    \n",
    "    removerows=['micro-avg','macro-avg']#,'Alarm_bell_ringing','Blender']\n",
    "\n",
    "\n",
    "    ind = np.arange(len(team['total duration'].drop(removerows)))\n",
    "    def myplot(ax,num,m):\n",
    "#         print(team[m])\n",
    "        \n",
    "        team_m=team[m][['Ntp','Nfn','Nfp']].drop(removerows,errors='ignore')\n",
    "        team_m=team_m.sort_index()\n",
    "        ind = np.arange(len(team_m))\n",
    "        cols=team_m\n",
    "        team_m=(team_m.T/team_m.sum(axis=1)).T\n",
    "        width = .8\n",
    "        marker = itertools.cycle(( '^', 'o', 'D', 's','X', '*'))\n",
    "        i=0\n",
    "#         ax.grid(True)\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(5,10))\n",
    "#         for i,x in enumerate(cols):\n",
    "#             if x=='y':continue\n",
    "#             print(team[m][x])\n",
    "#             ax.plot(team[m][x].T,ind+.2 ,label=x,marker=next(marker),alpha=.75)\n",
    "#             ax.scatter(total[x],ind+.2 ,label=x,marker=next(marker),alpha=.75)\n",
    "#             ax.barh(ind+.4-i*width, team[m][x], width, label=x)#, color='red'\n",
    "            \n",
    "        ax.barh(ind+.8, team_m['Ntp'], width, label='TP',color='g')#, color='red'\n",
    "        ax.barh(ind+.8, team_m['Nfn'], width,left=team_m['Ntp'], label='FN',color='#f6ff00',alpha=.25)#, color='red'\n",
    "        ax.barh(ind+.8, team_m['Nfp'], width,left=team_m[['Ntp','Nfn']].sum(axis=1), label='FP',color='r',alpha=1)#, color='red'\n",
    "        \n",
    "\n",
    "        ax.set(yticks=ind + width, yticklabels=[f'C{len(team_m)-i} : {y}' for i,y in enumerate(team_m.index)], ylim=[0.4, len(team_m)+.2],xlim=[0,1])\n",
    "        if num==4:\n",
    "            ax.legend(loc='upper center', bbox_to_anchor=(0, -0.35),fancybox=True, shadow=True, ncol=5)\n",
    "        ax.set_xlabel(m.replace(' ','\\n'))\n",
    "\n",
    "#     myplot(axs[0],np.append([0,1,len(total.columns)-1],range(2,len(total.columns)-5)))\n",
    "#     myplot(axs[0],[0,1,len(total.columns)-1,2,4,6])\n",
    "    # myplot(axs[1],[2])\n",
    "    ddd=pd.DataFrame(columns=['duration','events'])\n",
    "    gdurations=team['total duration'][['Ntp','Nfn']].drop(removerows).sum(axis=1).sort_index()\n",
    "    ddd['duration']=gdurations\n",
    "    print(gdurations)\n",
    "    gdp=gdurations/gdurations.sum()\n",
    "    pdurations=team['total duration'][['Ntp','Nfp']].drop(removerows).sum(axis=1).sort_index()\n",
    "    gevents=team['detection2'][['Ntp','Nfn']].drop(removerows).sum(axis=1).sort_index()\n",
    "    gep=gevents/gevents.sum()\n",
    "    ddd['events']=gevents\n",
    "    pevents=team['detection2'][['Ntp','Nfp']].drop(removerows).sum(axis=1).sort_index()\n",
    "#     ddd=ddd.astype(float)\n",
    "    ddd=ddd.applymap('{:,.0f}'.format)\n",
    "#     print(ddd)\n",
    "#     a=a.round()\n",
    "#     axs[0].barh(ind+1.1, gdp, .2, label='reference duration',color='g',alpha=.8)#, color='red'\n",
    "#     axs[0].barh(ind+.9, pdurations/pdurations.sum(), .2, color='b', label='prediction duration',alpha=1)#, color='red'\n",
    "#     axs[0].barh(ind+.7, gep, .2, label='reference count',color='y',alpha=.7)#, color='red'\n",
    "#     axs[0].barh(ind+.5, pevents/pevents.sum(), .2, label='prediction count',color='c',alpha=1)#, color='red'\n",
    "#     axs[0].legend(loc='upper center', bbox_to_anchor=(2, -0.25),fancybox=True, shadow=True, ncol=5)\n",
    "#     axs[0].set_xscale('log')\n",
    "#     the_table = axs[-1].table(\n",
    "#         cellText=ddd.values,\n",
    "#         loc='center',\n",
    "# #         colLabels=ddd.columns,\n",
    "#     )\n",
    "#     the_table.auto_set_font_size(False)\n",
    "#     the_table.set_fontsize(7)\n",
    "    \n",
    "\n",
    "    for i,m in enumerate(metrics):\n",
    "        myplot(axs[i],i,m)\n",
    "#     myplot(axs[1],range(len(total.columns)-8,len(total.columns)-1))\n",
    "    \n",
    "    # print(total)\n",
    "    plt.show()\n",
    "\n",
    "aliplot2(team)\n",
    "# total.sort_values(['events'],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T16:26:06.531219Z",
     "start_time": "2021-03-30T16:26:04.786571Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def aliplot3(team):\n",
    "    from matplotlib.pylab import plt\n",
    "    \n",
    "    allmetrics=list(team.keys())\n",
    "    removerows=['micro-avg','macro-avg']#,'Alarm_bell_ringing','Blender']\n",
    "    metrics=allmetrics\n",
    "#     total=total[-10:]\n",
    "    fig, axs = plt.subplots(1, len(metrics), figsize=(len(metrics), len(team[metrics[0]])/5), sharey=True)\n",
    "#     total=total.sort_values(['gem'])\n",
    "    import pandas\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    # colorcycle = cycler(color=['blue', 'orange', 'green', 'magenta'])\n",
    "    # Or use the default color cycle:\n",
    "    # colorcycle = cycler(color=plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "    \n",
    "    \n",
    "\n",
    "    gtf='/workspace/sed2020/metadata/public.tsv'\n",
    "    gt = pd.read_csv(gtf, sep=\"\\t\")\n",
    "\n",
    "    gt['duration']=gt.offset-gt.onset\n",
    "    print(gt['duration'].mean())\n",
    "    info=gt.groupby('event_label')['duration'].agg(['mean','std','count'])\n",
    "    info=info.loc[metrics]\n",
    "    print(info)\n",
    "    maxd=(info['mean']+info['std']).max().max();\n",
    "    print(maxd)\n",
    "    gt['duration']=maxd\n",
    "    info_n=info/maxd\n",
    "\n",
    "    avg_e_dur=pd.Series({m:team[m].loc['total duration'][['Ntp','Nfn']].sum()/team[m].loc['detection'][['Ntp','Nfn']].sum() for m in metrics})\n",
    "    avg_e_dur=pd.Series({m:team[m].loc['total duration'][['Ntp','Nfn']].sum()/team[m].loc['detection'][['Ntp','Nfn']].sum() for m in metrics})\n",
    "    e_count=pd.Series({m:team[m].loc['detection'][['Ntp','Nfn']].sum() for m in metrics})\n",
    "    \n",
    "#   \n",
    "    avg_e_dur=avg_e_dur/avg_e_dur.max()\n",
    "    print(e_count.max())\n",
    "    e_count=e_count/e_count.max()\n",
    "    \n",
    "    ind = np.arange(len(team[list(team.keys())[0]]))\n",
    "    def myplot(ax,num,m):\n",
    "#         print(team[m])\n",
    "        \n",
    "        team_m=team[m][['Ntp','Nfn','Nfp']]#.iloc[[0,6,8,2,1,12,10,11,9,13,14,15]]\n",
    "        \n",
    "#         team_m=team_m.sort_index()\n",
    "        ind = np.arange(len(team_m))\n",
    "        cols=team_m\n",
    "        team_m=(team_m.T/team_m.sum(axis=1)).T\n",
    "        width = .8\n",
    "        marker = itertools.cycle(( '^', 'o', 'D', 's','X', '*'))\n",
    "        i=0\n",
    "\n",
    "        ax.barh(ind+.8, team_m['Ntp'], width, label='TP',color='g')#, color='red'\n",
    "        ax.barh(ind+.8, team_m['Nfn'], width,left=team_m['Ntp'], label='FN',color='#f6ff00',alpha=.25)#, color='red'\n",
    "        ax.barh(ind+.8, team_m['Nfp'], width,left=team_m[['Ntp','Nfn']].sum(axis=1), label='FP',color='r',alpha=1)#, color='red'\n",
    "        \n",
    "        \n",
    "        ax.barh(-.2,e_count[m],width,label='Count')\n",
    "#         ax.barh(-1,avg_e_dur[m],width,label='Duration(avg)')\n",
    "        ax.barh(-1,info_n.loc[m]['mean'],width,label='Duration (std)')\n",
    "        ax.errorbar( info_n.loc[m]['mean'],-1.1, xerr=info_n.loc[m]['std'],color='black',elinewidth=1, fmt='-.')\n",
    "        all_data=gt['duration'][gt['event_label']==m]\n",
    "        \n",
    "        ax.set(yticks=ind + width, yticklabels=[f'{y}' for i,y in enumerate(team_m.index)], ylim=[0.4-2, len(team_m)+.2],xlim=[0,1])\n",
    "        if num==2:\n",
    "            ax.legend(loc='upper center', bbox_to_anchor=(0, -0.45),fancybox=True, shadow=True, ncol=5)\n",
    "        ax.set_xlabel(m.replace(' ','\\n').replace('bell_','').replace('_','\\n'))\n",
    "        \n",
    "\n",
    "#         ax.set_xticks(np.arange(0, 1, .5))\n",
    "        ax.set_xticks(np.arange(0, 1, .25), minor=True)\n",
    "\n",
    "        ax.grid(True,axis='x',which='both')\n",
    "\n",
    "    for i,m in enumerate(metrics):\n",
    "        myplot(axs[i],i,m)\n",
    "#     myplot(axs[1],range(len(total.columns)-8,len(total.columns)-1))\n",
    "    \n",
    "    # print(total)\n",
    "    plt.show()\n",
    "\n",
    "for s in ['Miyazaki_NU_SED_1','CTK_NU_SED_4','Hao_CQU_SED_4']:#total_dic:\n",
    "    print(s)\n",
    "    metrics=[m for m in total_dic[s]]\n",
    "    metrics=['collar','psd d/gtc=0.8','psd d/gtc=0.5','psd d/gtc=0.1','detection','segment','total duration','uniformity','relative duration']\n",
    "    team={m:total_dic[s][m] for m in metrics }\n",
    "\n",
    "#     metrics=list(team.keys())\n",
    "    clas=[c for c in team[metrics[0]].index[:-2]]\n",
    "#     clas=[c for i,c in enumerate(clas) if i in [0,2,3,4,9]]\n",
    "    clas=['Dishes',  'Cat', 'Speech', 'Blender','Alarm_bell_ringing']\n",
    "    print(clas)\n",
    "    team3={c:pd.DataFrame({m: team[m].loc[c] for m in metrics}).T for c in clas}\n",
    "#     print(team3)\n",
    "    aliplot3(team3)\n",
    "# total.sort_values(['events'],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T13:34:49.909570Z",
     "start_time": "2021-03-30T13:34:49.653710Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# example data\n",
    "x = np.arange(0.1, 4, 0.5)\n",
    "y = np.exp(-x)\n",
    "# example error bar values that vary with x-position\n",
    "error = 0.1 + 0.2 * x\n",
    "# error bar values w/ different -/+ errors\n",
    "lower_error = 0.4 * error\n",
    "upper_error = error\n",
    "asymmetric_error = [lower_error, upper_error]\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True)\n",
    "ax0.errorbar(x[0],-1, xerr=error[0], fmt='-o')\n",
    "ax0.set_title('variable, symmetric error')\n",
    "\n",
    "ax1.errorbar(x, y, xerr=asymmetric_error, fmt='o')\n",
    "ax1.set_title('variable, asymmetric error')\n",
    "ax1.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T07:30:37.553732Z",
     "start_time": "2021-03-29T07:30:37.544665Z"
    }
   },
   "outputs": [],
   "source": [
    "m='Blender'\n",
    "# print(team)\n",
    "# pd.DataFrame({m:team3[m].loc['total duration'][['Ntp','Nfn']].sum()})\n",
    "a={m:team3[m].loc['total duration'][['Ntp','Nfn']].sum()  for m in team3}\n",
    "a=pd.Series(a)/pd.Series(a).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T07:31:48.747477Z",
     "start_time": "2021-03-29T07:31:48.742881Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(a)/a.drop(['macro-avg','micro-avg']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Maker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:42:52.393301Z",
     "start_time": "2021-03-30T19:42:52.388097Z"
    }
   },
   "outputs": [],
   "source": [
    "def Convert2SED(g,p,duration,path=None):\n",
    "    \n",
    "    gdf=pd.DataFrame(g,columns=['onset','offset'])\n",
    "#     gdf=gdf/5\n",
    "    gdf['event_label']='Test'\n",
    "    gdf['filename']='Test'\n",
    "    gdf=gdf[['filename','onset','offset','event_label']]\n",
    "\n",
    "    pdf=pd.DataFrame(p,columns=['onset','offset'])\n",
    "#     pdf=pdf/6\n",
    "    pdf['event_label']='Test'\n",
    "    pdf['filename']='Test'\n",
    "    pdf=pdf[['filename','onset','offset','event_label']]\n",
    "    \n",
    "    meta_df=pd.DataFrame(columns=['filename','duration'])\n",
    "    meta_df['filename']=gdf['filename'].unique()\n",
    "#     meta_df['duration']=max(gdf['offset'].max(),pdf['offset'].max())\n",
    "    meta_df['duration']=duration\n",
    "    if path != None:\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        meta_df.to_csv(f'{path}/meta.tsv',sep='\\t',index=False)\n",
    "        pdf.to_csv(f'{path}/p.tsv',sep='\\t',index=False)\n",
    "        gdf.to_csv(f'{path}/g.tsv',sep='\\t',index=False)\n",
    "    return gdf,pdf,meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T22:19:25.410778Z",
     "start_time": "2021-03-30T22:19:25.405612Z"
    }
   },
   "outputs": [],
   "source": [
    "r[11:,:]+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all possible situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T10:31:12.284149Z",
     "start_time": "2021-03-31T10:31:10.867649Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SED.my_eval\n",
    "scale=2\n",
    "r=np.array([[2,3],[5,6],[9,10],[11,13],[14,17],[18,20],[22,24],[25,27],[30,31],[33,34],[37,38],[40., 45.],[47., 49.],[50., 51.],[52., 54.],[56., 61.],[62., 63.],[64., 67.]])/scale\n",
    "p=np.array([[1,2],[3,4],[7,8],[9,10],[11,12],[15,16],[19,20],[21,23],[26,28],[29,32],[33,35],[36,38],[39., 41.], [42., 43.], [44., 46.], [48., 53.], [55., 57.], [58., 59.], [60., 65.], [66., 68.]])/scale\n",
    "\n",
    "\n",
    "rdf,pdf,meta=Convert2SED(r,p,duration=69/scale)\n",
    "    \n",
    "\n",
    "res=SED.my_eval.get_single_result_df(rdf,pdf,meta,debug=1)\n",
    "res={m:res[m].loc['Test'][['Ntp','Nfn','Nfp']] for m in res}\n",
    "pd.DataFrame(res).T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T10:31:56.220659Z",
     "start_time": "2021-03-31T10:31:54.785679Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parts={ '1':{'r':range(0,11),'p':range(0,12)},\n",
    "        '2':{'r':range(11,12),'p':range(12,15)},\n",
    "        '3':{'r':range(12,15),'p':range(15,16)},\n",
    "        '4':{'r':range(15,18),'p':range(16,20)}  }\n",
    "all={}\n",
    "for part in parts:\n",
    "    r2=r[parts[part]['r'],:]\n",
    "    p2=p[parts[part]['p'],:]\n",
    "    mi=min(r2.min(),p2.min())-1\n",
    "    r2=r2-mi\n",
    "    p2=p2-mi\n",
    "    ma=max(r2.max(),p2.max())+1\n",
    "    rdf,pdf,meta=Convert2SED(r2,p2,duration=ma)\n",
    "\n",
    "#     print()\n",
    "    import SED.my_eval2\n",
    "    res=SED.my_eval.get_single_result_df(rdf,pdf,meta,debug=0)\n",
    "    res={m:res[m].loc['Test'][['Ntp','Nfn','Nfp']] for m in res}\n",
    "    all[f'Part {part}']=pd.DataFrame(res)\n",
    "\n",
    "# print(pd.DataFrame(res).T.round(1))\n",
    "\n",
    "# print(pd.concat(all).T.round(1))\n",
    "pd.concat(all).T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all).T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T18:30:49.486941Z",
     "start_time": "2021-03-28T18:30:49.166075Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SED.my_eval\n",
    "path=\"/tmp/test/\"\n",
    "\n",
    "g=[[2,3],[5,6]]\n",
    "p=[[1,2],[3,7]]\n",
    "saveTestSED(path,g,p,10)\n",
    "res=SED.my_eval.get_single_result(f'{path}/g.tsv',f'{path}/p.tsv',f'{path}/meta.tsv',debug=0)\n",
    "# for m in res:\n",
    "for m in ['segment','total duration']:\n",
    "    print(m)\n",
    "    print(pd.DataFrame(res[m][['Ntp','Nfp','Nfn','Ntn']]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:36:29.865846Z",
     "start_time": "2021-03-30T19:36:29.860065Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([[2,3],[5,6]],columns=['onset','offset'])\n",
    "# g=[[2,3],[5,6]]\n",
    "# p=[[1,2],[3,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:35:30.384838Z",
     "start_time": "2021-03-30T19:35:30.373218Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gtf='/workspace/sed2020/metadata/public.tsv'\n",
    "gt = pd.read_csv(gtf, sep=\"\\t\")\n",
    "gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:35:35.564799Z",
     "start_time": "2021-03-28T20:35:12.953052Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SED.my_eval\n",
    "path=\"/tmp/test/\"\n",
    "\n",
    "gtf='/workspace/sed2020/metadata/public.tsv'\n",
    "pef='/workspace/sed2020/submissions/CTK_NU/CTK_NU_task4_SED_1/public/CTK_NU_task4_SED_1.output.tsv'\n",
    "\n",
    "gt = pd.read_csv(gtf, sep=\"\\t\")\n",
    "    # Evaluate a single prediction\n",
    "pt = pd.read_csv(pef, sep=\"\\t\")\n",
    "\n",
    "clas=gt.event_label.append(pt.event_label).unique()\n",
    "    \n",
    "result={}\n",
    "for c in ['Blender']:\n",
    "        gtc=gt.loc[gt.event_label==c]\n",
    "        ptc=pt.loc[pt.event_label==c]\n",
    "        all=None\n",
    "        for f in gtc.filename.unique():\n",
    "            # if(c=='Blender'):debug=1\n",
    "#             print(f'============== class={c}=========file={f}')\n",
    "            g=gtc.loc[gtc.filename==f][['onset','offset']].values\n",
    "            p=ptc.loc[ptc.filename==f][['onset','offset']].values\n",
    "            saveTestSED(path,g,p,10)\n",
    "            res=SED.my_eval.get_single_result(f'{path}/g.tsv',f'{path}/p.tsv',f'{path}/meta.tsv',debug=0)\n",
    "            # for m in res:\n",
    "            out={}\n",
    "            out['segment']=res['segment'][['Ntp','Nfp','Nfn']].loc['Test']\n",
    "            out['total duration']=res['total duration'][['Ntp','Nfp','Nfn']].loc['Test']\n",
    "            out['diff']=out['segment']-out['total duration']\n",
    "            out=pd.DataFrame(out).T\n",
    "            if(all is None):\n",
    "                all=out\n",
    "            else:\n",
    "                all+=out\n",
    "            if (out.loc['diff']['Nfp'])>.1:\n",
    "                print(f'============== class={c}=========file={f}')\n",
    "                print(out)\n",
    "#             res=SED.my_eval.get_single_result(f'{path}/g.tsv',f'{path}/p.tsv',f'{path}/meta.tsv',debug=1)\n",
    "#             break\n",
    "#         break\n",
    "\n",
    "all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single file result direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T21:18:53.879761Z",
     "start_time": "2021-03-28T21:18:52.356282Z"
    }
   },
   "outputs": [],
   "source": [
    "print('ali')\n",
    "import pandas as pd\n",
    "import SED.my_eval\n",
    "path=\"/tmp/test/\"\n",
    "\n",
    "gtf='/workspace/sed2020/metadata/public.tsv'\n",
    "pef='/workspace/sed2020/submissions/CTK_NU/CTK_NU_task4_SED_1/public/CTK_NU_task4_SED_1.output.tsv'\n",
    "\n",
    "gt = pd.read_csv(gtf, sep=\"\\t\")\n",
    "    # Evaluate a single prediction\n",
    "pt = pd.read_csv(pef, sep=\"\\t\")\n",
    "\n",
    "clas=gt.event_label.append(pt.event_label).unique()\n",
    "    \n",
    "result={}\n",
    "for f in gt.filename.unique():\n",
    "\n",
    "        gtc=gt.loc[gt.filename==f]\n",
    "        ptc=pt.loc[pt.filename==f]\n",
    "        all=None\n",
    "        res=SED.my_eval.get_single_result_df(gtc,ptc,debug=0)\n",
    "        # for m in res:\n",
    "        out={}\n",
    "        out['segment']=res['segment'][['Ntp','Nfp','Nfn']].loc['Test']\n",
    "        out['total duration']=res['total duration'][['Ntp','Nfp','Nfn']].loc['Test']\n",
    "        out['diff']=out['segment']-out['total duration']\n",
    "        out=pd.DataFrame(out).T\n",
    "        if(all is None):\n",
    "            all=out\n",
    "        else:\n",
    "            all+=out\n",
    "        if (out.loc['diff']['Nfp'])>.1:\n",
    "            print(f'============== class={c}=========file={f}')\n",
    "            print(out)\n",
    "#             res=SED.my_eval.get_single_result(f'{path}/g.tsv',f'{path}/p.tsv',f'{path}/meta.tsv',debug=1)\n",
    "#             break\n",
    "#         break\n",
    "\n",
    "all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-28T20:36:38.627Z"
    }
   },
   "source": [
    "## single team test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T20:49:14.618640Z",
     "start_time": "2021-03-28T20:49:11.023327Z"
    }
   },
   "outputs": [],
   "source": [
    "print('ali')\n",
    "import pandas as pd\n",
    "import SED.my_eval\n",
    "gtf='/workspace/sed2020/metadata/public.tsv'\n",
    "pef='/workspace/sed2020/submissions/CTK_NU/CTK_NU_task4_SED_1/public/CTK_NU_task4_SED_1.output.tsv'\n",
    "res=SED.my_eval.get_single_result(gtf,pef,debug=0)\n",
    "out={}\n",
    "out['segment']=res['segment'][['Ntp','Nfp','Nfn']].loc['Blender']\n",
    "out['total duration']=res['total duration'][['Ntp','Nfp','Nfn']].loc['Blender']\n",
    "out['diff']=out['segment']-out['total duration']\n",
    "pd.DataFrame(out).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T12:14:38.424981Z",
     "start_time": "2021-03-30T12:14:38.410679Z"
    }
   },
   "outputs": [],
   "source": [
    "res2={c:res[c].loc['Test'] for c in res.keys() }\n",
    "print(pd.DataFrame(res2).T[ ['Nfn','Nfp','Ntp','precision','recall','f1' ]].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:10:59.313360Z",
     "start_time": "2021-03-25T17:10:58.085384Z"
    }
   },
   "outputs": [],
   "source": [
    "# total=pd.DataFrame(total).T\n",
    "# total['y']=total.index\n",
    "# print(total)\n",
    "# total2=total2[-20:-1]\n",
    "# total2=total\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Make the PairGrid\n",
    "g = sns.PairGrid(total2.sort_values(\"psds\", ascending=False),\n",
    "                 x_vars=total2.columns[0:-1], y_vars=['y'],\n",
    "                 height=len(total2.index)/2, aspect=4/len(total2.index))\n",
    "\n",
    "def qqplot(x, y, **kwargs):\n",
    "#     sns.stripplot\n",
    "    print(x.__dict__)\n",
    "    sns.stripplot(x=x, y=y, data=total,**kwargs)\n",
    "# Draw a dot plot using the stripplot function\n",
    "g.map(sns.stripplot, size=15, orient=\"h\", jitter=False,\n",
    "      palette=\"flare_r\", linewidth=1, edgecolor=\"w\")\n",
    "\n",
    "# Use the same x axis limits on all columns anmidmx add better lab+(mx-mi)/2els\n",
    "mx=total.max(axis=1).max()\n",
    "mi=total.min(axis=1).min()\n",
    "g.set(xlim=((mx+mi)/2,mx ), xlabel=\"F1\", ylabel=\"\")\n",
    "\n",
    "# Use semantically meaningful titles for the columns\n",
    "titles = total.columns[0:-1]\n",
    "\n",
    "for ax, title in zip(g.axes.flat, titles):\n",
    "\n",
    "    # Set a different title for each axes\n",
    "    ax.set(title=title)\n",
    "\n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:22:48.797122Z",
     "start_time": "2021-03-25T17:22:48.564838Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T18:17:40.496476Z",
     "start_time": "2021-03-25T18:17:40.493296Z"
    }
   },
   "outputs": [],
   "source": [
    "a=[1,2,3,4]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T12:43:23.241959Z",
     "start_time": "2021-03-12T12:43:22.131854Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total=pd.DataFrame(total).T\n",
    "# total['y']=total.index\n",
    "# print(total)\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Make the PairGrid\n",
    "g = sns.PairGrid(total.sort_values(\"gem-avg\", ascending=False),\n",
    "                 x_vars=total.columns[0:-1], y_vars=['y'],\n",
    "                 height=len(total.index)/2, aspect=4/len(total.index))\n",
    "\n",
    "f=lambda x,y: sns.barplot if(y==2) else sns.stripplot \n",
    "# Draw a dot plot using the stripplot function\n",
    "g.map(f, size=15, orient=\"h\", jitter=False,\n",
    "      palette=\"flare_r\", linewidth=1, edgecolor=\"w\")\n",
    "\n",
    "# Use the same x axis limits on all columns anmidmx add better lab+(mx-mi)/2els\n",
    "mx=total.max(axis=1).max()\n",
    "mi=total.min(axis=1).min()\n",
    "g.set(xlim=((mx+mi)/2,mx ), xlabel=\"F1\", ylabel=\"\")\n",
    "\n",
    "# Use semantically meaningful titles for the columns\n",
    "titles = total.columns[0:-1]\n",
    "\n",
    "for ax, title in zip(g.axes.flat, titles):\n",
    "\n",
    "    # Set a different title for each axes\n",
    "    ax.set(title=title)\n",
    "\n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "sns.despine(left=True, bottom=True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T15:00:22.629450Z",
     "start_time": "2021-03-25T15:00:18.700146Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#@interact\n",
    "#def result_selector(gtf=os.listdir(f'{rootFolder}/metadata/')):\n",
    "# import SED.my_eval\n",
    "gtf='public.tsv'\n",
    "rootFolder='/workspace/sed2020/'\n",
    "typ=gtf.split('.')[0]\n",
    "gtf=f'{rootFolder}/metadata/{gtf}'\n",
    "# meta_dur_df=pd.DataFrame(columns=['filename','duration'])\n",
    "# meta_dur_df['filename']=groundtruth['filename']\n",
    "# meta_dur_df['duration']=10\n",
    "total_dic={}\n",
    "for team in sorted(os.listdir(f'{rootFolder}/submissions/')):\n",
    "    print(f'analysing team {team}')\n",
    "    for code in sorted(os.listdir(f'{rootFolder}/submissions/{team}')):\n",
    "        print(f'    {code}')\n",
    "        base_prediction_path=f'{rootFolder}/submissions/{team}/{code}/{typ}/'\n",
    "        pef = f'{base_prediction_path}/{code}.output.tsv'\n",
    "        if not(os.path.isfile(pef)):\n",
    "            all=[x for x in os.listdir(base_prediction_path) if '.output.tsv' in x]\n",
    "            if len(all)>0:\n",
    "                pef=f'{base_prediction_path}/{all[0]}'\n",
    "            else:\n",
    "                print(pef)\n",
    "                continue\n",
    "        title=code.replace('_task4','')\n",
    "        groundtruth = pd.read_csv(gtf, sep=\"\\t\")\n",
    "        # Evaluate a single prediction\n",
    "        predictions = pd.read_csv(pef, sep=\"\\t\")\n",
    "        res1=SED.my_eval.get_single_result(gtf,pef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T15:00:39.000499Z",
     "start_time": "2021-03-25T15:00:38.992084Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T15:05:47.948920Z",
     "start_time": "2021-03-25T15:05:47.941093Z"
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "clas=groundtruth.event_label.append(predictions.event_label).unique()\n",
    "clas\n",
    "gt=groundtruth\n",
    "pt=predictions\n",
    "import metric\n",
    "# m=metric.GEM_NEW\n",
    "for c in clas:\n",
    "    gtc=gt.loc[gt.event_label==c]\n",
    "    ptc=pt.loc[pt.event_label==c]\n",
    "    \n",
    "    for f in gtc.filename.unique():\n",
    "        print(f'============== class={c}=========file={f}')\n",
    "        g=gtc.loc[gtc.filename==f][['onset','offset']].values\n",
    "        p=ptc.loc[ptc.filename==f][['onset','offset']].values\n",
    "#         print(eval_my_metric(g,p,(0,10)))\n",
    "        print(g)\n",
    "        break\n",
    "#         print('gtc',\n",
    "#         print('ptc',ptc.loc[ptc.filename==f]).apply(p=>(p.onset,p.offset))\n",
    "#         p=pt.loc[pt.event_label==c and pt.filename=g.filename]\n",
    "#         print(p)\n",
    "    break    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T15:11:53.122112Z",
     "start_time": "2021-03-25T15:11:53.118653Z"
    }
   },
   "outputs": [],
   "source": [
    "# g2=np.array(g)\n",
    "# g2=g2[g2[:,0].argsort(),:]\n",
    "# g2[0,:]=g[-1]*2\n",
    "# g2\n",
    "np.vstack((g,[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T13:57:38.627537Z",
     "start_time": "2021-03-25T13:57:38.605840Z"
    }
   },
   "outputs": [],
   "source": [
    "def intersection(e1,e2):    \n",
    "    inter=(max(e1[0],e2[0]),min(e1[1],e2[1]))\n",
    "    if(inter[1]<=inter[0]): \n",
    "        inter=None\n",
    "#     print(e1,e2,inter)\n",
    "    return inter\n",
    "\n",
    "def dur(e):\n",
    "    d= e[1]-e[0]\n",
    "    if(d<0):\n",
    "        print('erorr duration is less than zero' )\n",
    "    return d\n",
    "\n",
    "\n",
    "def eval_my_metric(real,pred,duration=(0,10),alpha=2,debug=0,calcne=1):\n",
    "        debug={'D':1,'T':1, 'M':1,'R':1,'V':1}#V:verbose\n",
    "        # real=merge_events_if_necessary(real)\n",
    "        # pred=merge_events_if_necessary(pred)\n",
    "        # real_tree=_makeIntervalTree(real,'r')\n",
    "        # pred_tree=_makeIntervalTree(pred,'p')\n",
    "        duration=(min(duration[0],real[0][0]),max(duration[1],real[-1][1]))\n",
    "        real=np.append(real,duration[1])# add a zero duration event in the end for ease comparision the last event\n",
    "        real[-1]=(duration[1],duration[1])\n",
    "        pred=np.append(pred,duration[1])# add a zero duration event in the end for ease comparision the last event\n",
    "        pred[-1]=(duration[1],duration[1])\n",
    "        #_ means negative\n",
    "        rel={'r+':{},'r-':{},'p+':{},'p-':{}}\n",
    "        print(real)\n",
    "        r_0=(duration[0],real[0][0])\n",
    "        r_n=(real[-1][1],duration[1])\n",
    "        metric={}\n",
    "        pi=0\n",
    "        rcalc=[]\n",
    "        real_=[]\n",
    "        pred_=[]\n",
    "        ri_=0\n",
    "        for ri in range(len(real)):\n",
    "            r=real[ri]\n",
    "            rp=real[ri-1] if ri>0 else (duration[0],duration[0])\n",
    "            r_=(rp[1],r[0])\n",
    "            \n",
    "            tmpr={'p+':{},'p-':{}}\n",
    "            tmpr_={'p+':{},'p-':{}}\n",
    "            rel['r+'][ri]=tmpr\n",
    "            \n",
    "            if(dur(r_)>0):\n",
    "                real_.append(r_)\n",
    "                ri_=len(real_)-1\n",
    "                rel['r-'][ri_]=tmpr_\n",
    "            \n",
    "            cond=pi<len(pred) \n",
    "            pi_=-1\n",
    "            while  cond:\n",
    "                pp=pred[pi-1] if pi>0 else (duration[0],duration[0])\n",
    "                p=pred[pi]\n",
    "                p_=(pp[1],p[0])\n",
    "                \n",
    "                if(dur(p_)>0 and (len(pred_)==0 or pred_[-1]!=p_)):\n",
    "                    pred_.append(p_)\n",
    "                pi_=len(pred_)-1\n",
    "\n",
    "                if not(pi in rel['p+']):\n",
    "                    rel['p+'][pi]={'r+':{},'r-':{}}\n",
    "                if not(pi_ in rel['p-']):\n",
    "                    rel['p-'][pi_]={'r+':{},'r-':{}}\n",
    "                tmpp=rel['p+'][pi]\n",
    "                tmpp_=rel['p-'][pi_]\n",
    "\n",
    "                rinter  =intersection(r,p)\n",
    "                rinter_ =intersection(r,p_)\n",
    "                r_inter =intersection(r_,p)                \n",
    "                r_inter_=intersection(r_,p_)\n",
    "                if(rinter is not None):\n",
    "                    # tmpr['p+'].append((pi,rinter))\n",
    "                    # tmpp['r+'].append((ri,rinter))\n",
    "                    tmpr['p+'][pi]=rinter\n",
    "                    tmpp['r+'][ri]=rinter\n",
    "                if(rinter_ is not None):\n",
    "                    # tmpr['p-'].append((pi,rinter_))\n",
    "                    # tmpp_['r+'].append((ri,rinter_))\n",
    "                    tmpr['p-'][pi_]=rinter_\n",
    "                    tmpp_['r+'][ri]=rinter_\n",
    "                if(r_inter is not None):\n",
    "                    # tmpr_['p+'].append((pi,r_inter))\n",
    "                    # tmpp['r-'].append((ri,r_inter))\n",
    "                    tmpr_['p+'][pi]=r_inter\n",
    "                    tmpp['r-'][ri_]=r_inter\n",
    "                if(r_inter_ is not None):\n",
    "                    # tmpr_['p-'].append((pi,r_inter_))\n",
    "                    # tmpp_['r-'].append((ri,r_inter_))\n",
    "                    tmpr_['p-'][pi_]=r_inter_\n",
    "                    tmpp_['r-'][ri_]=r_inter_\n",
    "                \n",
    "                \n",
    "                if pred[pi][1] < r[1]:\n",
    "                    pi+=1\n",
    "                else: cond=False\n",
    "                \n",
    "            \n",
    "            # for k in list(rel.keys()):\n",
    "            #     if len(rel[k])>0: continue\n",
    "            #     del rel[k]\n",
    "        \n",
    "        real=np.delete(real,-1,0)#real.pop()\n",
    "        pred=np.delete(pred,-1,0)#pred.pop()\n",
    "#         if(dur(pred_[-1])==0):pred_=np.delete(pred_,-1,0)\n",
    "#         if(dur(real_[-1])==0):real_=np.delete(real_,-1,0)\n",
    "\n",
    "        \n",
    "        out={\n",
    "            'detection':        {'tp':0,'fp':0,'fn':0,'tn':0},\n",
    "            'monotony':         {'tp':0,'fp':0,'fn':0,'tn':0},\n",
    "            'total duration':   {'tp':0,'fp':0,'fn':0,'tn':0},\n",
    "            'relative duration':{'tp':0,'fp':0,'fn':0,'tn':0}\n",
    "        }\n",
    "        \n",
    "        if debug['V']:\n",
    "            print(\"real=\",real)\n",
    "            print(\"pred=\",pred)\n",
    "            print(\"real_=\",real_)\n",
    "            print(\"pred_=\",pred_)\n",
    "            #for x in rel:\n",
    "            [print(f'{x}: {rel[x]}') for x in rel]\n",
    "        \n",
    "        for ri in range(len(real)):\n",
    "            tpd=int(len(rel['r+'][ri]['p+'])>0)\n",
    "            out['detection']['tp']+=tpd\n",
    "            if debug['D']: print(f\"D TP+{tpd}      ri={ri}, p+={rel['r+'][ri]['p+']}>0\")\n",
    "            #monotony {\n",
    "            if (len(rel['r+'][ri]['p+'])==1):\n",
    "                for rpi in rel['r+'][ri]['p+']:\n",
    "                    if len(rel['p+'][rpi]['r+'])==1:\n",
    "                        out['monotony']['tp']+=1\n",
    "                        if debug['M']:print(f\"M TP+1     rel[r+][{ri}][p+]={rel['r+'][ri]['p+']}==1 rel[p+][{rpi}][r+]={rel['p+'][rpi]['r+']}==1\")\n",
    "                    elif(len(rel['p+'][rpi]['r+'])==0):\n",
    "                        print('error it can not be zero')\n",
    "                    elif debug['M']:print(f\"M--tp rel[r+][{ri}][p+]={rel['r+'][ri]['p+']}==1 rel[p+][{rpi}][r+]={rel['p+'][rpi]['r+']}>1\")\n",
    "            #}\n",
    "            \n",
    "            for pi in rel['r+'][ri]['p+']:\n",
    "                tpt=dur(rel['r+'][ri]['p+'][pi])\n",
    "                tpr=tpt/dur(real[ri])\n",
    "                out['total duration']['tp']+=tpt\n",
    "                out['relative duration']['tp']+=tpr\n",
    "                if debug['T']:print(f\"T tp+={tpt}             rel[r+][{ri}][p+][{pi}]=dur({rel['r+'][ri]['p+'][pi]})\")\n",
    "                if debug['R']:print(f\"R tp+={tpr}             rel[r+][{ri}][p+][{pi}]==dur({rel['r+'][ri]['p+'][pi]}) / real[{ri}]=dur({real[ri]})\")\n",
    "                          \n",
    "            for pi in rel['r+'][ri]['p-']:\n",
    "                fnt=dur(rel['r+'][ri]['p-'][pi])\n",
    "                fnr=fnt/dur(real[ri])\n",
    "                out['total duration']['fn']+=fnt\n",
    "                out['relative duration']['fn']+=fnr\n",
    "                if debug['T']:print(f\"T fn+={fnt}             rel[r+][{ri}][p-][{pi}]=dur({rel['r+'][ri]['p-'][pi]})\")\n",
    "                if debug['R']:print(f\"R fn+={fnr}             rel[r+][{ri}][p-][{pi}]==dur({rel['r+'][ri]['p-'][pi]}) / real[{ri}]=dur({real[ri]})\")\n",
    "                \n",
    "\n",
    "        for ri in range(len(real_)):\n",
    "            tnd=int(len(rel['r-'][ri]['p-'])>0)\n",
    "            out['detection']['tn']+=tnd\n",
    "            if debug['D']: print(f\"D TN+{tnd}      ri-={ri}, p-={rel['r-'][ri]['p-']}>0\")\n",
    "            #monotony {\n",
    "            \n",
    "            if (len(rel['r-'][ri]['p-'])==1):\n",
    "                for rpi in rel['r-'][ri]['p-']:\n",
    "                    if len(rel['p-'][rpi]['r-'])==1:\n",
    "                        out['monotony']['tn']+=1\n",
    "                        if debug['M']:print(f\"M TN+1     rel[r-][{ri}][p-]={rel['r-'][ri]['p-']}==1 rel[p-][{rpi}][r-]={rel['p-'][rpi]['r-']}==1\")\n",
    "                    elif(len(rel['p-'][rpi]['r-'])==0):\n",
    "                        print('error it can not be zero')\n",
    "                    elif debug['M']:print(f\"M--tn rel[r-][{ri}][p-]={rel['r-'][ri]['p-']}==1 rel[p-][{rpi}][r-]={rel['p-'][rpi]['r-']}>1\")\n",
    "            #}\n",
    "\n",
    "            for pi in rel['r-'][ri]['p-']:\n",
    "                tnt=dur(rel['r-'][ri]['p-'][pi])\n",
    "                tnr=tnt/dur(real_[ri])\n",
    "                out['total duration']['tn']+=tnt\n",
    "                out['relative duration']['tn']+=tnr\n",
    "                if debug['T']:print(f\"T tn+={tnt}             rel[r-][{ri}][p-][{pi}]=dur({rel['r-'][ri]['p-'][pi]})\")\n",
    "                if debug['R']:print(f\"R tn+={tnr}             rel[r-][{ri}][p-][{pi}]==dur({rel['r-'][ri]['p-'][pi]}) / real_[{ri}]=dur({real_[ri]})\")\n",
    "            for pi in rel['r-'][ri]['p+']:\n",
    "                fpt=dur(rel['r-'][ri]['p+'][pi])\n",
    "                fpr=fpt/dur(real_[ri])\n",
    "                out['total duration']['fp']+=fpt\n",
    "                out['relative duration']['fp']+=fpr\n",
    "                if debug['T']:print(f\"T fp+={fpt}             rel[r-][{ri}][p+][{pi}]=dur({rel['r-'][ri]['p+'][pi]})\")\n",
    "                if debug['R']:print(f\"R fp+={fpr}             rel[r-][{ri}][p+][{pi}]==dur({rel['r-'][ri]['p+'][pi]}) / real_[{ri}]=dur({real_[ri]})\")\n",
    "\n",
    "        out['detection']['fp']=len(real_)-out['detection']['tn']\n",
    "        if debug['D']: print(f\"D fp={out['detection']['fp']} #r-={len(real_)} - tn={out['detection']['tn']}\"  )\n",
    "        out['detection']['fn']=len(real)-out['detection']['tp']\n",
    "        if debug['D']: print(f\"D fn={out['detection']['fn']} #r+={len(real)} - tp={out['detection']['tp']}\"  )\n",
    "                        \n",
    "        out['monotony']['fn']=len(real)-out['monotony']['tp']+len(pred_)-out['monotony']['tn']\n",
    "        if debug['M']: print(f\"M fn={out['monotony']['fn']}     #r+={len(real)} - tp={out['monotony']['tp']} + #p-={len(pred_)} - tn={out['monotony']['tn']}\")\n",
    "        out['monotony']['fp']=len(pred)-out['monotony']['tp']+len(real_)-out['monotony']['tn']\n",
    "        if debug['M']: print(f\"M fp={out['monotony']['fp']}     #p+={len(pred)} - tp={out['monotony']['tp']} + #r-={len(real_)} - tn={out['monotony']['tn']}\")\n",
    "        \n",
    "                        \n",
    "        for pi in range(len(pred)):\n",
    "            fpd=int(len(rel['p+'][pi]['r+'])==0)\n",
    "            out['detection']['fp']+=fpd\n",
    "            if debug['D']: print(f\"D FP+{fpd}      pi={pi}, r={rel['p+'][pi]['r+']}==0\")\n",
    "#             for ri in rel['p+'][pi]['r-']:\n",
    "#                 out['total duration']['fp']+=dur(rel['p+'][pi]['r-'][ri])\n",
    "#                 out['relative duration']['fp']+=dur(rel['p+'][pi]['r-'][ri])/dur(pred[pi])\n",
    "\n",
    "        for pi in range(len(pred_)):\n",
    "            fnd=int(len(rel['p-'][pi]['r-'])==0)\n",
    "            out['detection']['fn']+=fnd\n",
    "            if debug['D']: print(f\"D FN+{fnd}      pi-={pi}, r-={rel['p-'][pi]['r-']}==0\")\n",
    "#             for ri in rel['p-'][pi]['r+']:\n",
    "#                 out['total duration']['fn']+=dur(rel['p-'][pi]['r+'][ri])\n",
    "#                 out['relative duration']['fn']+=dur(rel['p-'][pi]['r+'][ri])/dur(pred_[pi])\n",
    "\n",
    "#         plot_events_with_event_scores(range(len(real)),range(len(pred)),real,pred)\n",
    "#         plot_events_with_event_scores(range(len(real_)),range(len(pred_)),real_,pred_)\n",
    "        if debug['V']:plot_events(real,pred,real_,pred_)\n",
    "        return  out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:00:55.110533Z",
     "start_time": "2021-03-25T14:00:55.103507Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_events(real,pred,real_,pred_, label=None):\n",
    "    from matplotlib.pylab import plt\n",
    "    import random\n",
    "    fig,ax = plt.subplots(figsize=(10, 2))\n",
    "    ax.set_title(label)\n",
    "    plt.xlim(0,max(real[-1][1],10))\n",
    "    ax.set_xticks(np.arange(0,max(real[-1][1],10),.1),minor=True)\n",
    "    maxsize=20\n",
    "    for i in range(min(maxsize,len(pred_))):\n",
    "        d = pred_[i]\n",
    "        plt.axvspan(d[0], d[1], 0, 0.4,linewidth=1,edgecolor='k',facecolor='m', alpha=.6)\n",
    "        plt.text((d[1] + d[0]) / 2, 0.1+random.random()/4,f'{i}' , horizontalalignment='center', verticalalignment='center')\n",
    "    for i in range(min(maxsize,len(pred))):\n",
    "        d = pred[i]\n",
    "        plt.axvspan(d[0], d[1], 0.1, 0.5,linewidth=1,edgecolor='k',facecolor='r', alpha=.6)\n",
    "        plt.text((d[1] + d[0]) / 2, 0.2+random.random()/4,f'{i}' , horizontalalignment='center', verticalalignment='center')\n",
    "#     maxsize=len(real)\n",
    "    for i in range(min(maxsize,len(real_))):\n",
    "        gt = real_[i]\n",
    "        plt.axvspan(gt[0], gt[1], 0.6, 1,linewidth=1,edgecolor='k',facecolor='y', alpha=.6)\n",
    "        plt.text((gt[1] + gt[0]) / 2, 0.6+random.random()/4,f'{i}' , horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "    for i in range(min(maxsize,len(real))):\n",
    "        gt = real[i]\n",
    "        plt.axvspan(gt[0], gt[1], 0.5, .9,linewidth=1,edgecolor='k',facecolor='g', alpha=.6)\n",
    "        plt.text((gt[1] + gt[0]) / 2, 0.5+random.random()/4,f'{i}' , horizontalalignment='center', verticalalignment='center')\n",
    "    plt.grid(True)\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
